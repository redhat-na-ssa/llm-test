{
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "disable_log_requests": true,
    "tensor_parallel_size": 4,
    "trust_remote_code": true,
    "gpu_memory_utilization": 0.95,
    "block_size": 32,
    "enforce_eager": true,
    "enable_chunked_prefill": true,
    "max_num_batched_tokens": 8192,
    "max_num_seqs": 50,
    "max_model_len": 8192
}
